# LocalChatBot

## ì‚¬ìš©ë°©ë²•

### 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

``` bash
# hugginface transformers, pytorch required
cd ./models && python3 down_models.py --model-name deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
```

### 2. í™˜ê²½ì„¤ì •

ì‚¬ìš© í™˜ê²½ì— ë§ê²Œ ë³€ê²½

```bash
# .env

export MODEL_NAME=Qwen2.5-0.5B-Instruct
export SERVED_MODEL_NAME=ChatBot
export GPU_MEMORY_UTILIZATION=0.8

export WEBUI_PORT=3000
```

### 3. ì‹¤í–‰

```bash
bash launch.sh
```

## Advanced

### ì‚¬ìš©ì¤‘ì¸ GPUì˜ compute capabilityê°€ 80 ì´ìƒì´ë©´ ğŸ‘‰ Flash Attention, V1 engine, bf16 ì‚¬ìš©

ì•„ë˜ì²˜ëŸ¼ VLLM_USE_V1, VLLM_ATTENTION_BACKEND bfloat16 ì˜µì…˜ ì¶”ê°€í•˜ì—¬ ì‚¬ìš©

```yaml
services:
  vllm:
    ...
    entrypoint: python3 -m vllm.entrypoints.openai.api_server
    ...
    --dtype bfloat16 # ğŸ‘ˆ
    ...
    environment:
      - VLLM_USE_V1 1  # ğŸ‘ˆ
      - VLLM_ATTENTION_BACKEND: "FLASH_ATTN"  # ğŸ‘ˆ
```

### GPU 2ê°œ ì´ìƒ ì“¸ ìˆ˜ ìˆë‹¤ ğŸ‘‰ Tensor Parallel ì‚¬ìš© (ë°©ë²•ì€ ë”°ë¡œ ì—°ë½)



